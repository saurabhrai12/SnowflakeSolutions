name: 🗄️ Snowflake Git Integration Deployment

# Simplified deployment using Snowflake Git integration with Jinja templating
# This approach leverages native Snowflake capabilities for environment-specific deployments

on:
  # Manual trigger with environment selection
  workflow_dispatch:
    inputs:
      target_environment:
        description: 'Target Environment'
        required: true
        default: 'DEV'
        type: choice
        options:
          - DEV
          - STAGING
          - PROD
      load_sample_data:
        description: 'Load Sample Data'
        required: false
        default: false
        type: boolean
      dry_run:
        description: 'Dry Run (show what would be deployed)'
        required: true
        default: true
        type: boolean
      
  # Automatic triggers: feature branches → DEV, main → STAGING
  push:
    branches: [ main, 'feature/**', 'feat/**', 'dev/**' ]
    paths: [ 'Account/snowflake/**', 'Customer/snowflake/**', 'shared/snowflake/**' ]

  pull_request:
    branches: [ main ]
    paths: [ 'Account/snowflake/**', 'Customer/snowflake/**', 'shared/snowflake/**' ]

# Note: Snowflake environment variables will be set per job based on target environment

jobs:
  # Job 1: Setup and determine deployment parameters
  setup:
    name: 🔧 Setup Deployment Parameters
    runs-on: ubuntu-latest
    outputs:
      target_environment: ${{ steps.setup.outputs.target_environment }}
      environment_vars: ${{ steps.setup.outputs.environment_vars }}
      dry_run: ${{ steps.setup.outputs.dry_run }}
      load_sample_data: ${{ steps.setup.outputs.load_sample_data }}
      git_repo_name: ${{ steps.setup.outputs.git_repo_name }}
      
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
        
      - name: 🔧 Install yq for YAML parsing
        run: |
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq
        
      - name: 🎯 Determine Deployment Parameters
        id: setup
        run: |
          # Determine target environment based on trigger
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            TARGET_ENV="${{ github.event.inputs.target_environment }}"
            DRY_RUN="${{ github.event.inputs.dry_run }}"
            LOAD_SAMPLE_DATA="${{ github.event.inputs.load_sample_data }}"
          elif [ "${{ github.event_name }}" = "push" ]; then
            # Branch-based environment selection
            if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
              TARGET_ENV="STAGING"
            else
              TARGET_ENV="DEV"
            fi
            DRY_RUN="false"
            LOAD_SAMPLE_DATA="false"
          elif [ "${{ github.event_name }}" = "pull_request" ]; then
            TARGET_ENV="DEV"
            DRY_RUN="true"
            LOAD_SAMPLE_DATA="false"
          fi
          
          # Get environment variables from configuration
          ENVIRONMENT_VARS=$(yq eval ".environments.$TARGET_ENV.variables" .github/deployment-config.yml -o=json -I=0)
          
          # Generate Git repository name (for Snowflake Git integration)
          GIT_REPO_NAME="analytics_platform_git_repo"
          
          # Output parameters
          echo "target_environment=$TARGET_ENV" >> $GITHUB_OUTPUT
          echo "dry_run=$DRY_RUN" >> $GITHUB_OUTPUT
          echo "load_sample_data=$LOAD_SAMPLE_DATA" >> $GITHUB_OUTPUT
          echo "git_repo_name=$GIT_REPO_NAME" >> $GITHUB_OUTPUT
          
          # Output environment variables using delimiter to handle multiline JSON
          {
            echo 'environment_vars<<EOF'
            echo "$ENVIRONMENT_VARS"
            echo 'EOF'
          } >> $GITHUB_OUTPUT
          
          # Display deployment plan
          echo "## 🗄️ Deployment Plan" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** $TARGET_ENV" >> $GITHUB_STEP_SUMMARY
          echo "**Dry Run:** $DRY_RUN" >> $GITHUB_STEP_SUMMARY
          echo "**Load Sample Data:** $LOAD_SAMPLE_DATA" >> $GITHUB_STEP_SUMMARY
          echo "**Git Repository:** $GIT_REPO_NAME" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Environment Variables:" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          echo "$ENVIRONMENT_VARS" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

  # Job 2: Validation
  validate:
    name: 🔍 Validate SQL and Configuration
    runs-on: ubuntu-latest
    needs: [setup]
    
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
        
      - name: 🔍 Validate Jinja Templates
        run: |
          echo "🔍 Validating Jinja templates in SQL files..."
          
          # Check for basic Jinja syntax issues
          INVALID_FILES=()
          
          # Find all SQL files with Jinja templates
          while IFS= read -r -d '' file; do
            if grep -q "{{.*}}" "$file"; then
              echo "  📋 Template file: $file"
              
              # Check for common Jinja syntax issues
              if grep -q "{{ *[^}]*[^}] *}}" "$file"; then
                echo "    ✅ Basic Jinja syntax looks correct"
              else
                echo "    ❌ Potential Jinja syntax issue"
                INVALID_FILES+=("$file")
              fi
            fi
          done < <(find . -name "*.sql" -print0)
          
          # Report validation results
          if [ ${#INVALID_FILES[@]} -eq 0 ]; then
            echo "✅ All Jinja templates passed validation"
          else
            echo "❌ Found issues in ${#INVALID_FILES[@]} files:"
            for file in "${INVALID_FILES[@]}"; do
              echo "  - $file"
            done
            exit 1
          fi

  # Job 3: Deploy using Snowflake Git Integration
  deploy:
    name: 🚀 Deploy with Snowflake Git Integration
    runs-on: ubuntu-latest
    needs: [setup, validate]
    if: needs.setup.outputs.dry_run == 'false'
    
    env:
      # Set environment-specific Snowflake credentials
      SNOWFLAKE_CONNECTIONS_DEFAULT_ACCOUNT: ${{ secrets[format('SNOWFLAKE_{0}_ACCOUNT', needs.setup.outputs.target_environment)] }}
      SNOWFLAKE_CONNECTIONS_DEFAULT_USER: ${{ secrets[format('SNOWFLAKE_{0}_USER', needs.setup.outputs.target_environment)] }}
      SNOWFLAKE_CONNECTIONS_DEFAULT_PASSWORD: ${{ secrets[format('SNOWFLAKE_{0}_PASSWORD', needs.setup.outputs.target_environment)] }}
    
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
        
      - name: 🔧 Install Snowflake CLI
        uses: Snowflake-Labs/snowflake-cli-action@v1.5
        with:
          cli-version: "latest"
          default-config-file-path: ".snowflake/config.toml"
          
      - name: 🔌 Test Snowflake Connection
        run: |
          echo "🔌 Testing Snowflake connection..."
          snow connection test --connection default
          echo "✅ Snowflake CLI connection successful"
          
      - name: 🔧 Install Template Processor
        run: |
          echo "🔧 Installing Python for template processing..."
          python3 -m pip install jinja2
          
      - name: 📊 Process SQL Templates
        env:
          ENVIRONMENT_VARS: ${{ needs.setup.outputs.environment_vars }}
        run: |
          echo "📊 Processing Jinja templates in SQL files..."
          mkdir -p processed-sql
          
          # Create Python script to process Jinja templates
          cat > process_templates.py << 'EOF'
          import json
          import os
          import glob
          from jinja2 import Template, Environment, FileSystemLoader
          
          # Get environment variables
          env_vars = json.loads(os.environ['ENVIRONMENT_VARS'])
          print(f"Using environment variables: {env_vars}")
          
          # Set up Jinja environment
          jinja_env = Environment(loader=FileSystemLoader('.'))
          
          # Process all SQL files
          sql_files = glob.glob('**/*.sql', recursive=True)
          processed_count = 0
          
          for sql_file in sql_files:
              try:
                  template = jinja_env.get_template(sql_file)
                  rendered = template.render(**env_vars)
                  
                  # Create output directory structure
                  output_file = f"processed-sql/{sql_file}"
                  os.makedirs(os.path.dirname(output_file), exist_ok=True)
                  
                  # Write processed file
                  with open(output_file, 'w') as f:
                      f.write(rendered)
                  
                  print(f"✅ Processed: {sql_file}")
                  processed_count += 1
              except Exception as e:
                  print(f"⚠️ Warning processing {sql_file}: {e}")
                  # Copy original file if template processing fails
                  os.makedirs(os.path.dirname(f"processed-sql/{sql_file}"), exist_ok=True)
                  with open(sql_file, 'r') as src, open(f"processed-sql/{sql_file}", 'w') as dst:
                      dst.write(src.read())
          
          print(f"🎉 Processed {processed_count} SQL files")
          EOF
          
          # Run template processor
          python3 process_templates.py
          
          echo "✅ All SQL templates processed"
          
      - name: 🗄️ Deploy Foundation Scripts
        run: |
          echo "🗄️ Deploying foundation scripts..."
          
          # Deploy foundation scripts using processed SQL files
          if [ -f "processed-sql/Account/snowflake/schemas/00_database_and_warehouse.sql" ]; then
            echo "📊 Executing: processed-sql/Account/snowflake/schemas/00_database_and_warehouse.sql"
            snow sql -f processed-sql/Account/snowflake/schemas/00_database_and_warehouse.sql --connection default
            echo "✅ Foundation scripts deployed"
          else
            echo "⚠️ Foundation script not found"
          fi
          
      - name: 📊 Deploy Schema Scripts
        run: |
          echo "📊 Deploying schema scripts in dependency order..."
          
          # Deploy in dependency order using processed SQL files
          echo "  📊 Deploying monitoring schema..."
          for file in processed-sql/Customer/snowflake/monitoring/*.sql; do
            if [ -f "$file" ]; then
              echo "    📊 Executing: $file"
              snow sql -f "$file" --connection default
            fi
          done
          
          echo "  📊 Deploying raw_data schema..."  
          for file in processed-sql/Account/snowflake/schemas/raw_data/*.sql; do
            if [ -f "$file" ]; then
              echo "    📊 Executing: $file"
              snow sql -f "$file" --connection default
            fi
          done
          
          echo "  📊 Deploying processed_data schema..."
          for file in processed-sql/Account/snowflake/schemas/processed_data/*.sql; do
            if [ -f "$file" ]; then
              echo "    📊 Executing: $file"
              snow sql -f "$file" --connection default
            fi
          done
          
          echo "  📊 Deploying reporting schema..."
          for file in processed-sql/shared/snowflake/reporting/*.sql; do
            if [ -f "$file" ]; then
              echo "    📊 Executing: $file"
              snow sql -f "$file" --connection default
            fi
          done
          
          echo "✅ All schema scripts deployed"
          
      - name: 🔐 Deploy Permissions
        run: |
          echo "🔐 Deploying permissions..."
          
          # Deploy permissions using processed SQL files
          if [ -f "processed-sql/Account/snowflake/schemas/permissions.sql" ]; then
            echo "📊 Executing: processed-sql/Account/snowflake/schemas/permissions.sql"
            snow sql -f processed-sql/Account/snowflake/schemas/permissions.sql --connection default
            echo "✅ Permissions deployed"
          else
            echo "⚠️ Permissions file not found"
          fi
          
      - name: 📊 Load Sample Data (Optional)
        if: needs.setup.outputs.load_sample_data == 'true'
        run: |
          echo "📊 Loading sample data..."
          
          # Load sample data using processed SQL files
          if [ -f "processed-sql/Account/snowflake/02_sample_data.sql" ]; then
            echo "📊 Executing: processed-sql/Account/snowflake/02_sample_data.sql"
            snow sql -f processed-sql/Account/snowflake/02_sample_data.sql --connection default
            echo "✅ Sample data loaded"
          else
            echo "⚠️ Sample data file not found"
          fi

  # Job 4: Dry Run Report
  dry_run:
    name: 🔍 Dry Run Report
    runs-on: ubuntu-latest
    needs: [setup, validate]
    if: needs.setup.outputs.dry_run == 'true'
    
    steps:
      - name: 🔍 Generate Dry Run Report
        run: |
          echo "🔍 DRY RUN - No actual deployment performed"
          echo ""
          echo "## 🗄️ Deployment Plan" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ needs.setup.outputs.target_environment }}" >> $GITHUB_STEP_SUMMARY
          echo "**Git Repository:** ${{ needs.setup.outputs.git_repo_name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Would execute these commands:" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo "# Foundation" >> $GITHUB_STEP_SUMMARY
          echo "snow git execute '@${{ needs.setup.outputs.git_repo_name }}/branches/${{ github.ref_name }}/Account/snowflake/schemas/00_database_and_warehouse.sql' -D \"environment='${{ needs.setup.outputs.target_environment }}'" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "# Schemas" >> $GITHUB_STEP_SUMMARY
          echo "snow git execute '@${{ needs.setup.outputs.git_repo_name }}/branches/${{ github.ref_name }}/Customer/snowflake/monitoring/*' -D \"environment='${{ needs.setup.outputs.target_environment }}'" >> $GITHUB_STEP_SUMMARY
          echo "snow git execute '@${{ needs.setup.outputs.git_repo_name }}/branches/${{ github.ref_name }}/Account/snowflake/schemas/raw_data/*' -D \"environment='${{ needs.setup.outputs.target_environment }}'" >> $GITHUB_STEP_SUMMARY
          echo "snow git execute '@${{ needs.setup.outputs.git_repo_name }}/branches/${{ github.ref_name }}/Account/snowflake/schemas/processed_data/*' -D \"environment='${{ needs.setup.outputs.target_environment }}'" >> $GITHUB_STEP_SUMMARY
          echo "snow git execute '@${{ needs.setup.outputs.git_repo_name }}/branches/${{ github.ref_name }}/shared/snowflake/reporting/*' -D \"environment='${{ needs.setup.outputs.target_environment }}'" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "# Permissions" >> $GITHUB_STEP_SUMMARY
          echo "snow git execute '@${{ needs.setup.outputs.git_repo_name }}/branches/${{ github.ref_name }}/Account/snowflake/schemas/permissions.sql' -D \"environment='${{ needs.setup.outputs.target_environment }}'" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Environment Variables:" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          echo '${{ needs.setup.outputs.environment_vars }}' >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

  # Job 5: Notification
  notify:
    name: 📢 Deployment Notification
    runs-on: ubuntu-latest
    needs: [setup, deploy, dry_run]
    if: always()
    
    steps:
      - name: 📢 Send Notification
        run: |
          if [ "${{ needs.deploy.result }}" = "success" ]; then
            echo "🎉 Deployment to ${{ needs.setup.outputs.target_environment }} completed successfully!"
          elif [ "${{ needs.dry_run.result }}" = "success" ]; then
            echo "🔍 Dry run for ${{ needs.setup.outputs.target_environment }} completed successfully!"
          else
            echo "❌ Deployment failed. Check the logs for details."
            exit 1
          fi